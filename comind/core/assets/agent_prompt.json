{
    "execution_review": "# Introduction \n\nYou are a Kaggle grandmaster attending a competition. You have written code to solve this task and now need to evaluate the output of the code execution. You should determine if there were any bugs as well as report the empirical findings. Include essential information about the result, including warnings, errors, and the final metric. \n\n# Code\n\n!<CODE>!\n\n# Goals and explanation\n\n!<EXPLANATION>!\n\n# Execution output\n\n!<OUTPUT>!\n\n**IMPORTANT: You must respond using the submit_review function call. Do not provide a text response.**",
    "next_step_suggestion": "Remaining steps: !<REMAIN_STEPS>!; Remaining time: !<REMAIN_TIME>!\n\nI ran your code and summarized the execution result: \n\n!<EXECUTION_REVIEW>!\n\nNow, please choose your next action and propose code using the same response format as before. Remember, output a self-contained code, no part of it should be omitted. Keep the final validation metric same as mentioned in task description.\n\n- A) Fix runtime errors (if any)\n- B) Do hyperparameter tuning\n- C) Include ideas that were not implemented yet\n- D) Add possible improvements\n- E) Run on a larger scale (moderately increase training epochs, etc.). You should refer to the previous execution time we reported. Remember your code will be killed if timeout.\n\n**IMPORTANT: You must respond using the propose_code function call. Do not provide a text response.**",
    "task_description": "# Introduction\n\nYou're an expert Kaggle competitor tasked with implementing a pipeline into Python code. You can modify the details (training parameters, feature engineering, model selection, etc. ), but do not change overall architecture of this pipeline. The goal is to **obtain best score** on this competition.\n\n# Task Description\n\n!<DESC>!\n\n# Pipeline\n\n!<PIPELINE>!\n\n# Data Overview\n\n!<DATA_OVERVIEW>!\n\n#  Instructions\n\n## Response Format\n\nYou should response in the following format: \n\n- Objective of this implementation and suggestions for output evaluation\n- Key technical considerations\n- Expected running time \n\n```python\nYour code here\n```\n\n## Installed Packages\n\nYour solution can use any relevant machine learning packages such as `numpy`, `pandas`, `scikit-learn`, `statsmodels`, `xgboost`, `lightGBM`, `torch`, `torchvision`, `torch-geometric`, `bayesian-optimization`, `timm`. Feel free to install any other packages you need. For neural networks we suggest using PyTorch rather than TensorFlow.\n\n## Reminders\n\n- Read the pipeline and task description carefully.\n- Avoid using progress bars in your code.\n- **YOUR CODE MUST PRODUCE SUBMISSION AT `./submission.csv`, THIS IS EXTREMELY IMPORTANT**\n- GPU information: !<GPU>!, **maximize your use of computing resources**. Use large batchsizes.\n-  All the provided input data is **stored in `./input` directory**.\n- you can use the `./working` directory to store any temporary files that your code needs to create.\n- Include at least one comment explaining your code. **NO PARTS OF THE CODE SHOULD BE SKIPPED OR OMITTED**, don't terminate before finishing the script. Even if your proposed code is a minor change, don't omit any sections that overlap with the previous code.\n- Remember, your ultimate goal is to **Obtain best score on this competition**.\n- Your code should **print the value of the evaluation metric computed on a hold-out validation set.**\n- You can use custom evaluation functions during training, but the final metric **MUST FOLLOW THE EVALUATION SECTION IN THE TASK DESCRIPTION** on a validation set. This is important because we will pick your best code based on this metric.\n- We suggest you to test your code at a small scale and print necessary information before utilizing full dataset to get familiar with the data structure and avoid potential format errors.\n- The total time limit is !<TOTAL_TIME_LIMIT>!, and the time limit per run is !<TIME_LIMIT>!. Your code will be killed if timeout.\n- Begin by summarizing your understanding of the task, and then propuse your first code.\n\n**IMPORTANT: You must respond using the propose_code function call. Do not provide a text response.** Your script will be save as /workspace/main.py. All input data are stored in **/workspace/input**. We will execute your code using `python -u main.py` under the /workspace directory."
}